{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Scikit-Learn(sklearn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We shall be dealing with some of the most beautiful functions of the Scikit learn library.\n",
    "#we are going to cover--\n",
    "what_to_cover=['0.an end to end scikit workflow',\n",
    "'1.getting our data ready',\n",
    "'2.Choose the right estimator(model) for our problems.',\n",
    "'3.Fit the model/estimator to our data to make predictions.',\n",
    "'4.Evaluate our model.',\n",
    "'5.Improve our Model through experimentation.',\n",
    "'6.Save and load a trained model.',\n",
    "'7.Put it all together!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.an end to end scikit workflow',\n",
       " '1.getting our data ready',\n",
       " '2.Choose the right estimator(model) for our problems.',\n",
       " '3.Fit the model/estimator to our data to make predictions.',\n",
       " '4.Evaluate our model.',\n",
       " '5.Improve our Model through experimentation.',\n",
       " '6.Save and load a trained model.',\n",
       " '7.Put it all together!']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what_to_cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.An end to end scikit workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. Get the data ready\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "heart_disease=pd.read_csv('https://raw.githubusercontent.com/mrdbourke/zero-to-mastery-ml/master/data/heart-disease.csv')\n",
    "heart_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create X which is features matrix\n",
    "X= heart_disease.drop('target',axis=1)\n",
    "#Create Y which is label matrix\n",
    "Y= heart_disease['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. Choose the right model and hyperparameters\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf =RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#We will keep the default hyperparameters\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sklearn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-4c34a5b0fa30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_versions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sklearn' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "sklearn.show_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Fit the Model to the traning data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a prediction\n",
    "Y_label=clf.predict(np.array([1,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_preds=clf.predict(X_test)\n",
    "Y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Evaluate the Model on the training data and the test data\n",
    "clf.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "print(classification_report(Y_test,Y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_test,Y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(Y_test,Y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Improve your Model\n",
    "#Try different types of hyperparameters(n_estimators)\n",
    "np.random.seed(100)\n",
    "for i in range(10,100,10):\n",
    "    print(f'Trying model with {i} estimators')\n",
    "    clf=RandomForestClassifier(n_estimators=i).fit(X_train,Y_train)\n",
    "    print(f'Model accuracy on test set: {clf.score(X_test,Y_test)*100}')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. save a model and load it\n",
    "import pickle\n",
    "\n",
    "pickle.dump(clf,open('heart-disease-prediction-using-random-forest.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model=pickle.load(open('heart-disease-prediction-using-random-forest.pkl','rb'))\n",
    "loaded_model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.getting our data ready for machine learning\n",
    "\n",
    "3 main things which we have to do--\n",
    "  1. Split the data into features and labels(usually 'X' and 'y')\n",
    "  2. Filling(imputing) or disregarding missing values.\n",
    "  3. Converting non-numerical values to numerical values(featuring values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=heart_disease.drop('target',axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=heart_disease['target']\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into traning and test data set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,X_test.shape,Y_train.shape,Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales=pd.read_csv('car-sales-extended.csv')\n",
    "car_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(car_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X and Y which is the feature and target labels\n",
    "X=car_sales.drop('Price',axis=1)\n",
    "Y=car_sales['Price']\n",
    "\n",
    "#Split the data into test and training data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Machine Learning Model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model=RandomForestRegressor()\n",
    "model.fit(X_train,Y_train)\n",
    "model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales[\"Doors\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder #turn the categories into numbers\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features=['Make',\"Colour\",\"Doors\"]\n",
    "one_hot=OneHotEncoder()\n",
    "transformer=ColumnTransformer([('one_hot',one_hot,categorical_features)],remainder=\"passthrough\")\n",
    "transformed_X=transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(transformed_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies=pd.get_dummies(car_sales[[\"Make\",\"Colour\",\"Doors\"]])\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since now our data is all in 0s and 1s so let's try and refit our model\n",
    "np.random.seed(23)\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(transformed_X,Y,test_size=0.2)\n",
    "model.fit(X_train,Y_train)\n",
    "model.fit(X_test,Y_test)\n",
    "model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.What if there were some missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Fill them with some values(imputations).\n",
    "#2. Remove all the data associated with missing data alltogether.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing=pd.read_csv('car-sales-extended-missing-data.csv')\n",
    "car_sales_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create X and Y\n",
    "X=car_sales_missing.drop('Price',axis=1)\n",
    "Y=car_sales_missing['Price']\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try and convert our data in numbers\n",
    "from sklearn.preprocessing import OneHotEncoder #turn the categories into numbers\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features=['Make',\"Colour\",\"Doors\"]\n",
    "one_hot=OneHotEncoder()\n",
    "transformer=ColumnTransformer([('one_hot',one_hot,categorical_features)],remainder=\"passthrough\")\n",
    "transformed_X=transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill missing data with Pandas(Option 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill the Make Column\n",
    "car_sales_missing[\"Make\"].fillna('missing',inplace=True)\n",
    "\n",
    "#Fill the Colour Column\n",
    "car_sales_missing[\"Colour\"].fillna('missing',inplace=True)\n",
    "\n",
    "#Fill the Odometer Column\n",
    "car_sales_missing[\"Odometer (KM)\"].fillna(car_sales_missing['Odometer (KM)'].mean(),inplace=True)\n",
    "\n",
    "#Fill the Doors Column\n",
    "car_sales_missing[\"Doors\"].fillna(4,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's check our Dataframe again\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing Price value\n",
    "car_sales_missing.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(car_sales_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=car_sales_missing.drop(\"Price\",axis=1)\n",
    "Y=car_sales_missing[\"Price\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'car_sales_missing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-cb0fc50f8589>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mColumnTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'one_hot'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcategorical_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mremainder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"passthrough\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtransformed_X\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcar_sales_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mtransformed_X\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'car_sales_missing' is not defined"
     ]
    }
   ],
   "source": [
    "#Let's try and convert our data to numbers\n",
    "from sklearn.preprocessing import OneHotEncoder #turn the categories into numbers\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features=['Make',\"Colour\",\"Doors\"]\n",
    "one_hot=OneHotEncoder()\n",
    "transformer=ColumnTransformer([('one_hot',one_hot,categorical_features)],remainder=\"passthrough\")\n",
    "transformed_X=transformer.fit_transform(car_sales_missing)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fill Missing values with Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing=pd.read_csv('car-sales-extended-missing-data.csv')\n",
    "car_sales_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.dropna(subset=['Price'],inplace=True)\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X and y\n",
    "X=car_sales_missing.drop('Price',axis=1)\n",
    "y=car_sales_missing[\"Price\"]\n",
    "\n",
    "#Split into training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(24)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill missing values with Scikit Learn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#Fill categorical values with missing and numerical value with mean\n",
    "cat_imputer=SimpleImputer(strategy='constant',fill_value='missing')\n",
    "door_imputer=SimpleImputer(strategy='constant',fill_value=4)\n",
    "num_imputer=SimpleImputer(strategy='mean')\n",
    "\n",
    "#Define Columnns\n",
    "cat_features=[\"Make\",\"Colour\"]\n",
    "door_features=[\"Doors\"]\n",
    "num_features=[\"Odometer (KM)\"]\n",
    "\n",
    "#Create an Imputer which fills in missing values\n",
    "imputer=ColumnTransformer([\n",
    "    ('cat_imputer',cat_imputer,cat_features),\n",
    "    ('door_imputer',door_imputer,door_features),\n",
    "    ('num_imputer',num_imputer,num_features)\n",
    "    ])\n",
    "\n",
    "#Transform the data\n",
    "filled_X_train=imputer.fit_transform(X_train)\n",
    "filled_X_test=imputer.transform(X_test)\n",
    "\n",
    "filled_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our transformed data array's back into DataFrame's\n",
    "car_sales_filled_train = pd.DataFrame(filled_X_train, \n",
    "                                      columns=[\"Make\", \"Colour\", \"Doors\", \"Odometer (KM)\"])\n",
    "\n",
    "car_sales_filled_test = pd.DataFrame(filled_X_test, \n",
    "                                     columns=[\"Make\", \"Colour\", \"Doors\", \"Odometer (KM)\"])\n",
    "\n",
    "# Check missing data in training set\n",
    "car_sales_filled_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OneHotEncoder class from sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Now let's one hot encode the features with the same code as before \n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\", \n",
    "                                 one_hot, \n",
    "                                 categorical_features)],\n",
    "                                 remainder=\"passthrough\")\n",
    "\n",
    "# Fill train and test values separately\n",
    "transformed_X_train = transformer.fit_transform(car_sales_filled_train)\n",
    "transformed_X_test = transformer.transform(car_sales_filled_test)\n",
    "\n",
    "# Check transformed and filled X_train\n",
    "transformed_X_train.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets fit our data to our model\n",
    "np.random.seed(34)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model=RandomForestRegressor()\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "model.fit(transformed_X_train,y_train)\n",
    "model.fit(transformed_X_test,y_test)\n",
    "model.score(transformed_X_test,y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(car_sales_filled_test),len(car_sales_filled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "what_to_cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2.Choosing the right estimator/algorithm for our problem\n",
    "Scikit learn uses estimator in place of machine learning model or algorithm.\n",
    "* Classification\n",
    "* Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Picking a machine learning model for our regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import boston housing dataset\n",
    "from sklearn.datasets import load_boston\n",
    "boston=load_boston()\n",
    "boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df=pd.DataFrame(boston[\"data\"],columns=boston[\"feature_names\"])\n",
    "boston_df['target']=pd.Series(boston['target'])\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many samples?\n",
    "len(boston_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try the ridge regression model\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "#Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#Create the data\n",
    "X=boston_df.drop('target',axis=1)\n",
    "y=boston_df['target']\n",
    "\n",
    "#Split into training and test data sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "#Instantiate the Ridge Model\n",
    "model=Ridge()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#Check the score of ridge model on test data\n",
    "model.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How do we improve the accuracy of our model?\n",
    "for i in range(10):\n",
    "    model=Ridge(alpha=i/10)\n",
    "    model.fit(X_train,y_train)\n",
    "    a= model.score(X_test,y_test)\n",
    "    \n",
    "    print(f'The accuracy of our model for alpha={i/10} is {a}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we improve this score?\n",
    "\n",
    "What if our model was not working upto the mark?\n",
    "\n",
    "Head back to the map for more information-- https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try the RandomForest regression model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#Create the data\n",
    "X=boston_df.drop('target',axis=1)\n",
    "y=boston_df['target']\n",
    "\n",
    "#Split into training and test data sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "#Instantiate the Ridge Model\n",
    "model=RandomForestRegressor()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#Check the score of ridge model on test data\n",
    "model.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How do we improve the accuracy of our model?\n",
    "np.random.seed(23)\n",
    "for i in range(10,100,10):\n",
    "    model=RandomForestRegressor(n_estimators=i)\n",
    "    model.fit(X_train,y_train)\n",
    "    a= model.score(X_test,y_test)\n",
    "    \n",
    "    print(f'The accuracy of our model for n_estimators={i} is {a}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##2.2 Choosing the estimator for a Classification Problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease=pd.read_csv('https://raw.githubusercontent.com/mrdbourke/zero-to-mastery-ml/master/data/heart-disease.csv')\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(heart_disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consulting the map and it say to try out linear svc\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "#Setup random seed\n",
    "np.random.seed(43)\n",
    "\n",
    "#Get your data ready\n",
    "X=heart_disease.drop('target',axis=1)\n",
    "y=heart_disease['target']\n",
    "\n",
    "#Split your data into training and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "#Now lets fit our training data to the model\n",
    "clf=LinearSVC(max_iter=1000)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "#Now lets check the performance of our model\n",
    "clf.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consulting the map and it say to try out RandomForest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Setup random seed\n",
    "np.random.seed(4)\n",
    "\n",
    "#Get your data ready\n",
    "X=heart_disease.drop('target',axis=1)\n",
    "y=heart_disease['target']\n",
    "\n",
    "#Split your data into training and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "#Now lets fit our training data to the model\n",
    "clf=RandomForestClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "#Now lets check the performance of our model\n",
    "clf.score(X_test,y_test)\n",
    "\n",
    "#Setup random seed\n",
    "np.random.seed(100)\n",
    "\n",
    "#Get your data ready\n",
    "X=heart_disease.drop('target',axis=1)\n",
    "y=heart_disease['target']\n",
    "\n",
    "#Split your data into training and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "#Now lets fit our training data to the model\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "#Now lets check the performance of our model\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some General Advice\n",
    "   ### If you have structured data, use ensemble methods.\n",
    "\n",
    "   ### If you have unstructured data, use deep learning or transfer learning based methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "what_to_cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Fitting our model to the data and using it to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Fitting the model to the data\n",
    "#### Different names for--\n",
    " * X=Features,feature variable, data\n",
    " * y=target,label,target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consulting the map and it say to try out RandomForest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Setup random seed\n",
    "np.random.seed(4)\n",
    "\n",
    "#Get your data ready\n",
    "X=heart_disease.drop('target',axis=1)\n",
    "y=heart_disease['target']\n",
    "\n",
    "#Split your data into training and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "#Now lets fit our training data to the model\n",
    "clf=RandomForestClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "#Now lets check the performance of our model\n",
    "clf.score(X_test,y_test)\n",
    "\n",
    "#Setup random seed\n",
    "np.random.seed(100)\n",
    "\n",
    "#Get your data ready\n",
    "X=heart_disease.drop('target',axis=1)\n",
    "y=heart_disease['target']\n",
    "\n",
    "#Split your data into training and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "#Now lets fit our training data to the model\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "#Now lets check the performance of our model\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Make preditions using Machine Learning Model\n",
    "#### 2 ways to make predictions--\n",
    "    *predict()\n",
    "    *predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use a trained model to make predictions\n",
    "y_preds=clf.predict(X_test)\n",
    "y_preds\n",
    "np.mean(y_preds == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions with predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_proba() returns probabilities of a classification label\n",
    "y_preds=clf.predict_proba(X_test[:5])\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's predict on the same data\n",
    "y_preds=clf.predict(X_test[:5])\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* predict() can also be used for regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try the RandomForest regression model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#Create the data\n",
    "X=boston_df.drop('target',axis=1)\n",
    "y=boston_df['target']\n",
    "\n",
    "#Split into training and test data sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "#Instantiate the Model and train it\n",
    "model=RandomForestRegressor().fit(X_train,y_train)\n",
    "\n",
    "#Check the score of ridge model on test data\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds=model.predict(X_test)\n",
    "y_preds[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare the predictions with the true values\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Evaluating a Machine Learning Model\n",
    "* 3 ways to evaluate Scikit-learn model/estimator\n",
    "   * score() method\n",
    "   * 'scoring' parameter\n",
    "   * Problem-specific metric functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Using the score() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(37)\n",
    "\n",
    "X=heart_disease.drop('target',axis=1)\n",
    "y=heart_disease['target']\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "model=RandomForestClassifier().fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's do the same for regression\n",
    "\n",
    "#Let's try the RandomForest regression model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#Create the data\n",
    "X=boston_df.drop('target',axis=1)\n",
    "y=boston_df['target']\n",
    "\n",
    "#Split into training and test data sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "#Instantiate the Model and train it\n",
    "model=RandomForestRegressor().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the score of ridge model on test data\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Evaluating our model with the 'scoring paramter' (Cross-Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(37)\n",
    "\n",
    "X=heart_disease.drop('target',axis=1)\n",
    "y=heart_disease['target']\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=100).fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(clf,X,y,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(clf,X,y,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(37)\n",
    "\n",
    "#Single training and test split score\n",
    "clf_single_score=clf.score(X_test,y_test)\n",
    "\n",
    "#Take mean of 5 cross-validation score\n",
    "clf_cross_val_score=np.mean(cross_val_score(clf,X,y,cv=5))\n",
    "clf_cross_val_score\n",
    "\n",
    "#Compare the 2 scores \n",
    "clf_single_score,clf_cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default scoring param of classification is mean accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring paramter set to null by default\n",
    "cross_val_score(clf,X,y,cv=5,scoring=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Classification Model Evaluation metrics\n",
    "\n",
    "* accuracy\n",
    "* area under ROC curve\n",
    "* Confusion Matrix\n",
    "* Classification Report\n",
    "\n",
    "#### accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(37)\n",
    "\n",
    "X=heart_disease.drop('target',axis=1)\n",
    "y=heart_disease['target']\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=100).fit(X_train,y_train)\n",
    "\n",
    "cross_val_score=np.mean(cross_val_score(clf,X,y,cv=5))\n",
    "cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'heart disease classifier Cross-validated accuracy is: {cross_val_score*100:.2f}% ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area under the Receiver Operating Characterstic Curve(ROC) **\n",
    "* Area under Curve(AUC)\n",
    "* ROC Curve\n",
    "\n",
    "* ROC is a comparison of a model's true positive rate(tpr) versus its false positive rate(fpr)\n",
    "\n",
    "* True Positive= Model predicts 1 and the target is 1\n",
    "* False Positive= Model predicts 1and the target is 0\n",
    "* True negative= Model predicts 0 when target is 0\n",
    "* False negative= Model predicts 0 when target is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the features and target\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "#Make predictions with probabilities\n",
    "y_probs=clf.predict_proba(X_test)\n",
    "y_probs[:10],len(y_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_positive=y_probs[:,1]\n",
    "y_probs_positive[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate fpr,tpr and threshold \n",
    "fpr,tpr,threshold=roc_curve(y_test,y_probs_positive)\n",
    "\n",
    "#check the fpr rate\n",
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function for plotting roc curves\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_roc_curve(fpr,tpr):\n",
    "    '''\n",
    "    plots ouur roc curve guven fpr and tpr(true-positive-rate)\n",
    "    '''\n",
    "    plt.plot(fpr,tpr,color='Red',label=\"ROC\")\n",
    "    \n",
    "    #plot line with no predictive power\n",
    "    plt.plot([0,1],[0,1],color=\"Blue\",linestyle='--',label=\"guessing\")\n",
    "    \n",
    "    \n",
    "    plt.xlabel('False positive rate(fpr)')\n",
    "    plt.ylabel('True positive rate(tpr)')\n",
    "    plt.title('Receiver Operating Charactersitc(ROC) curve')\n",
    "    \n",
    "plot_roc_curve(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test,y_probs_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot perfect roc curve and AUC(area under curve) score\n",
    "\n",
    "fpr,tpr,thresholds=roc_curve(y_test,y_test)\n",
    "\n",
    "plot_roc_curve(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "It is a quick way to compare the lables a model predicts and the actual labels it was supposed to predict.\n",
    "\n",
    "In essence giving you an idea about where your model is getting confused!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_preds=clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise confusion matrix with pd.crosstab\n",
    "\n",
    "pd.crosstab(y_test,y_preds,rownames=[\"Actual label\"],colnames=[\"Predicted labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "31+28+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make our Confusion Matrix more visual with Seaborn's heatmap()\n",
    "import seaborn as sns\n",
    "\n",
    "#Set the font scale\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "#Create a confusion matrix\n",
    "confusion_matrix=confusion_matrix(y_test,y_preds)\n",
    "\n",
    "#Plot it using Seaborn\n",
    "sns.heatmap(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(confusion_matrix):\n",
    "    '''\n",
    "    Plots a Confusion Matrix using Seaborn's Heatmap\n",
    "    '''\n",
    "    \n",
    "    fig,ax=plt.subplots(figsize=(3,3))\n",
    "    ax=sns.heatmap(confusion_matrix,annot=True,cbar=False)\n",
    "    plt.xlabel(\"true label\")\n",
    "    plt.ylabel(\"predicted label\")\n",
    "    \n",
    "plot_confusion_matrix(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(clf,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarising Classification Metrics--\n",
    "* Accuracy is good if our classes are balanced.\n",
    "* Precision and Recall becomes important when our classes are imbalanced.\n",
    "* F1 score is a combination of Precision and Recall.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Regression Model Evaluation Metrics\n",
    "Model evaluation metrics Documentation--https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "    \n",
    "* R**2 or co-effecient of determination\n",
    "* Mean Absolute Error.\n",
    "* Mean squared error.\n",
    "\n",
    "#### R^2\n",
    "\n",
    "** Compares your model's prediction to the mean of the target, its value can range from -infinity to 1.\n",
    "** How close the data is fitted to our regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(37)\n",
    "\n",
    "X=boston_df.drop('target',axis=1)\n",
    "y=boston_df['target']\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "model=RandomForestRegressor(n_estimators=100).fit(X_train,y_train)\n",
    "\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_preds=model.predict(X_test)\n",
    "\n",
    "r2_score(y_test,y_preds) #R^2 is the default metric in case of regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_mean=np.full(len(y_test),y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,y_test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean absolute error(MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mean_absolute_error(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data={'actual values':y_test,'predicted values':y_preds})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['difference']=df['actual values']-df['predicted values']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['squared_difference']=df['difference'].apply(lambda x:x**2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['squared_difference'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* R^2 here is pretty much similar to accuracy in classification.\n",
    "* MAE is a good indicator of how far your predictions are from the actual values on an average.\n",
    "* MSE amplifies the difference of MAE as it uses square."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 Finally dealing with the 'Scoring' Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(23)\n",
    "\n",
    "X=heart_disease.drop('target',axis=1)\n",
    "y=heart_disease['target']\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(32)\n",
    "cv_score=cross_val_score(clf,X,y,cv=5,scoring=None)\n",
    "cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-Validated Accuracy\n",
    "print(f'the cross validated accuracy is: {np.mean(cv_score)*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(32)\n",
    "cv_score=cross_val_score(clf,X,y,cv=5,scoring='accuracy')\n",
    "print(f'the cross validated accuracy is: {np.mean(cv_score)*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(32)\n",
    "cv_precision=cross_val_score(clf,X,y,cv=5,scoring='precision')\n",
    "print(f'the cross validated precision is: {np.mean(cv_precision)*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision\n",
    "np.random.seed(32)\n",
    "cv_precision=cross_val_score(clf,X,y,cv=5,scoring='precision')\n",
    "print(f'the cross validated precision is: {np.mean(cv_precision)*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recall\n",
    "np.random.seed(32)\n",
    "cv_recall=cross_val_score(clf,X,y,cv=5,scoring='recall')\n",
    "print(f'the cross validated recall is: {np.mean(cv_recall)*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(32)\n",
    "cv_f1=cross_val_score(clf,X,y,cv=5,scoring='f1')\n",
    "print(f'the cross validated f1 score is: {np.mean(cv_f1)*100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about our regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "np.random.seed(21)\n",
    "\n",
    "X=boston_df.drop('target',axis=1)\n",
    "y=boston_df['target']\n",
    "\n",
    "model=RandomForestRegressor(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_r2=cross_val_score(model,X,y,cv=5)\n",
    "cv_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_r2=cross_val_score(model,X,y,cv=5,scoring='r2')\n",
    "cv_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Absolute Error\n",
    "cv_mae=cross_val_score(model,X,y,cv=5,scoring='neg_mean_absolute_error')\n",
    "cv_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Squared Error\n",
    "cv_mse=cross_val_score(model,X,y,cv=5,scoring='neg_mean_squared_error')\n",
    "cv_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "what_to_cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Using different Evaluation metrics as Scikit-learn Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the methods we used above like accuract,precision etc can directly be imported and used as an sklearn function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Improving our Model\n",
    "\n",
    "* First Predictions= Baseline predictions\n",
    "* First Model= Baseline Model\n",
    "\n",
    "Improving our model from a data perspective--\n",
    "* Could we collect more data?(The more data the better)\n",
    "* Could we improve our data?(More depth of Information)\n",
    "\n",
    "From a Model Perspective--\n",
    "* Could we use a better model?\n",
    "* Could we improve the current model?\n",
    "\n",
    "3 ways to adjust HyperParameters--\n",
    "* By hand.\n",
    "* randomly with RandomSearchCV\n",
    "* exhaustively with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf=RandomForestClassifier()\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Tuning HyperParameters by hand\n",
    "Let's make 3 sets i.e training,validation and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We're going to try and adjust the following--\n",
    "\n",
    "* max_depth\n",
    "* max_features\n",
    "* min_samples_leaf\n",
    "* min_samples_split\n",
    "* n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score,precision_score,f1_score,accuracy_score\n",
    "\n",
    "def evaluate_preds(y_true,y_preds):\n",
    "    '''\n",
    "    Compare evaluation comparison on y_test labels and y_preds labels on a classification model\n",
    "    '''\n",
    "    accuracy=accuracy_score(y_true,y_preds)\n",
    "    precision=precision_score(y_true,y_preds)\n",
    "    recall=recall_score(y_true,y_preds)\n",
    "    f1=f1_score(y_true,y_preds)\n",
    "    \n",
    "    metric_dict={\n",
    "        'accuracy':round(accuracy,2),\n",
    "        'precision':round(precision,2),\n",
    "        'recall':round(recall,2),\n",
    "        'f1':round(f1,2)\n",
    "    }\n",
    "    print(f'accuracy is {accuracy*100:.2f}%')\n",
    "    print(f'precision is {precision*100:.2f}%')\n",
    "    print(f'recall is {recall*100:.2f}%')\n",
    "    print(f'f1 is {f1*100:.2f}%')\n",
    "    \n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#Shuffle the data\n",
    "heart_disease_shuffled=heart_disease.sample(frac=1)\n",
    "\n",
    "#Split into X and Y\n",
    "X=heart_disease_shuffled.drop('target',axis=1)\n",
    "y=heart_disease_shuffled['target']\n",
    "\n",
    "#Split into test,train and validation data\n",
    "train_split=round(0.7*len(heart_disease_shuffled))\n",
    "valid_split=round(train_split+0.15*len(heart_disease_shuffled))\n",
    "\n",
    "\n",
    "X_train,y_train=X[:train_split],y[:train_split]\n",
    "X_valid,y_valid=X[train_split:valid_split],y[train_split:valid_split]\n",
    "X_test,y_test=X[valid_split:],y[valid_split:]\n",
    "\n",
    "len(X_train),len(X_valid),len(X_test)\n",
    "\n",
    "clf=RandomForestClassifier()\n",
    "\n",
    "clf.get_params()\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "#make baseline predictions\n",
    "y_preds=clf.predict(X_valid)\n",
    "\n",
    "#Evaluate the classifier on Validation set\n",
    "baseline_metrics=evaluate_preds(y_valid,y_preds)\n",
    "baseline_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(37)\n",
    "\n",
    "#Create another classifier with different Hyperparameters\n",
    "clf2=RandomForestClassifier(n_estimators=50)\n",
    "\n",
    "clf2.fit(X_train,y_train)\n",
    "\n",
    "#Make predictions with different HyperParameters\n",
    "y_preds_2=clf2.predict(X_valid)\n",
    "\n",
    "#Evaluate the second Classifier\n",
    "clf2_metrics=evaluate_preds(y_valid,y_preds_2)\n",
    "clf2_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_3=RandomForestClassifier(n_estimators=100,max_depth=10)\n",
    "\n",
    "clf_3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 HyperParameter tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "grid={'n_estimators':[10,100,200,500,1000,1200],'max_depth':['None',5,10,20,30],\n",
    "      'max_features':['auto','sqrt'],'min_samples_split':[2,4,6],\n",
    "      'min_samples_leaf':[1,2,3]\n",
    "     }\n",
    "\n",
    "np.random.seed(23)\n",
    "\n",
    "#Split into X and Y\n",
    "X=heart_disease_shuffled.drop('target',axis=1)\n",
    "y=heart_disease_shuffled['target']\n",
    "\n",
    "# Split into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "# Instantiate our classifier\n",
    "clf=RandomForestClassifier(n_jobs=1)\n",
    "\n",
    "# set up RandomizedSearchCV\n",
    "rs_clf=RandomizedSearchCV(estimator=clf,param_distributions=grid,\n",
    "                         n_iter=10,\n",
    "                         cv=5,\n",
    "                         verbose=2)\n",
    "\n",
    "#Fit the previous model\n",
    "rs_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's make predictions with the best parameters\n",
    "rs_y_preds=rs_clf.predict(X_test)\n",
    "\n",
    "#Evaluate the predictions\n",
    "rs_metrics=evaluate_preds(y_test,rs_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_2={\n",
    " 'n_estimators': [ 100, 200, 500,],\n",
    " 'max_depth': [None],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_split': [6],\n",
    " 'min_samples_leaf': [1, 2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "\n",
    "np.random.seed(34)\n",
    "\n",
    "#Split into X and Y\n",
    "X=heart_disease_shuffled.drop('target',axis=1)\n",
    "y=heart_disease_shuffled['target']\n",
    "\n",
    "# Split into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "# Instantiate our classifier\n",
    "clf=RandomForestClassifier(n_jobs=1)\n",
    "\n",
    "# set up RandomizedSearchCV\n",
    "grid_clf=GridSearchCV(estimator=clf,param_grid=grid_2,\n",
    "                      cv=5,\n",
    "                      verbose=2)\n",
    "\n",
    "#Fit the previous model\n",
    "grid_clf.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's make predictions with the best parameters\n",
    "grid_clf_y_preds=grid_clf.predict(X_test)\n",
    "\n",
    "#Evaluate the predictions\n",
    "grid_metrics=evaluate_preds(y_test,rs_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's Compare our different model metrics\n",
    "\n",
    "compare_metrics=pd.DataFrame({'baseline':baseline_metrics,\n",
    "                              'randomized':rs_metrics,\n",
    "                              'grid':grid_metrics\n",
    "                             })\n",
    "compare_metrics.plot.bar(figsize=(10,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "what_to_cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Saving and Loading our Machine Learning Models\n",
    "\n",
    "2 ways to do it--\n",
    "1. With the 'pickle' module\n",
    "2. With the 'joblib' module\n",
    "\n",
    "#### Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#Save an existing model to a file\n",
    "pickle.dump(rs_clf,open('./random-forest-model-1.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load a save model\n",
    "loaded_pickle_model=pickle.load(open('random-forest-model-1.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_pickle_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make some predictions using our loaded model\n",
    "\n",
    "\n",
    "y_preds=loaded_pickle_model.predict(X_test)\n",
    "\n",
    "evaluate_preds(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using 'Joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump,load\n",
    "\n",
    "#save model to file\n",
    "dump(rs_clf,filename=\"random-forest-model-2.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model from a file\n",
    "\n",
    "loaded_joblib_model=load(filename=\"random-forest-model-2.joblib\")\n",
    "loaded_joblib_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib_y_preds=loaded_joblib_model.predict(X_test)\n",
    "\n",
    "evaluate_preds(joblib_y_preds,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.an end to end scikit workflow',\n",
       " '1.getting our data ready',\n",
       " '2.Choose the right estimator(model) for our problems.',\n",
       " '3.Fit the model/estimator to our data to make predictions.',\n",
       " '4.Evaluate our model.',\n",
       " '5.Improve our Model through experimentation.',\n",
       " '6.Save and load a trained model.',\n",
       " '7.Put it all together!']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what_to_cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Putting it all together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>35820.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>155144.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>66604.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>215883.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>248360.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12732.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Make Colour  Odometer (KM)  Doors    Price\n",
       "0     Honda  White        35431.0    4.0  15323.0\n",
       "1       BMW   Blue       192714.0    5.0  19943.0\n",
       "2     Honda  White        84714.0    4.0  28343.0\n",
       "3    Toyota  White       154365.0    4.0  13434.0\n",
       "4    Nissan   Blue       181577.0    3.0  14043.0\n",
       "..      ...    ...            ...    ...      ...\n",
       "995  Toyota  Black        35820.0    4.0  32042.0\n",
       "996     NaN  White       155144.0    3.0   5716.0\n",
       "997  Nissan   Blue        66604.0    4.0  31570.0\n",
       "998   Honda  White       215883.0    4.0   4001.0\n",
       "999  Toyota   Blue       248360.0    4.0  12732.0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('car-sales-extended-missing-data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make              object\n",
       "Colour            object\n",
       "Odometer (KM)    float64\n",
       "Doors            float64\n",
       "Price            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps we want to do,all in one cell--\n",
    "1. Fill Missing data\n",
    "2. Convert data to numbers.\n",
    "3. Build a Model on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting our data ready\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Modelling\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "\n",
    "# Set up random seed\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# Import our data\n",
    "data=pd.read_csv('car-sales-extended-missing-data.csv')\n",
    "data.dropna(subset=[\"Price\"],inplace=True)\n",
    "\n",
    "# Define different features and transformer pipelines\n",
    "categorical_features=['Make','Colour']\n",
    "categorical_transformer=Pipeline(steps=[\n",
    "    ('imputer',SimpleImputer(strategy='constant',fill_value=\"missing\")),\n",
    "     ('onehot',OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "door_feature=[\"Doors\"]\n",
    "door_transformer=Pipeline(steps=[\n",
    "    ('imputer',SimpleImputer(strategy='constant',fill_value=4)])\n",
    "\n",
    "numeric_features=[\"Odometer (KM)\"]\n",
    "numeric_transformer=Pipeline(steps=[\n",
    "    ('imputer',SimpleImputer(strategy='mean')])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
